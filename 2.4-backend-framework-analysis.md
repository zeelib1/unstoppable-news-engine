# Backend Framework Analysis for AskFiles

**Date:** 2026-01-28 16:25 CET  
**Question:** Should we use Laravel or switch to something else?  
**Context:** About to implement first issue, good time to reconsider

---

## Current Situation

**What we have:**
- Laravel 11 backend (already set up)
- Nuxt 3 frontend
- Qdrant for vector search (separate service)
- OpenAI for embeddings (external API)
- Docling for document processing (Python scripts)

**What the backend actually does:**
1. Receive file upload
2. Queue document processing job
3. Call Docling (Python) to extract text
4. Call OpenAI to generate embeddings
5. Store vectors in Qdrant
6. Store metadata in SQLite/PostgreSQL
7. Handle search requests (query Qdrant, return results)

---

## Framework Options

### Option 1: Keep Laravel (PHP)
**Pros:**
- ✅ Already set up (save 2-3 days)
- ✅ Excellent file upload handling
- ✅ Great queue system (async processing)
- ✅ Eloquent ORM for metadata
- ✅ Huge ecosystem (packages for everything)
- ✅ Good for CRUD APIs
- ✅ Great documentation

**Cons:**
- ❌ PHP slower than Go/Rust (but not the bottleneck here)
- ❌ Heavier memory footprint
- ❌ Not ideal for real-time/streaming
- ❌ Might be overkill for simple API

**Performance:**
- ~500-1000 req/sec (single server)
- Good enough for <10K users

---

### Option 2: FastAPI (Python)
**Pros:**
- ✅ Same language as Docling pipeline
- ✅ Very fast (async native)
- ✅ Perfect for ML/AI projects
- ✅ Automatic OpenAPI docs
- ✅ Great typing support

**Cons:**
- ❌ Need to rebuild everything (2-3 days)
- ❌ Less mature ecosystem than Laravel
- ❌ Async can be tricky
- ❌ Python packaging can be messy

**Performance:**
- ~2000-3000 req/sec
- Better for CPU-heavy tasks

---

### Option 3: Go + Gin/Fiber
**Pros:**
- ✅ Very fast (~10K req/sec)
- ✅ Low memory footprint
- ✅ Concurrent by default
- ✅ Single binary deployment
- ✅ Great for APIs

**Cons:**
- ❌ Need to rebuild everything (3-4 days)
- ❌ More verbose than Laravel
- ❌ Smaller ecosystem for AI/ML
- ❌ Error handling can be tedious

**Performance:**
- ~10,000 req/sec
- Excellent for high-load

---

### Option 4: Node.js + Fastify
**Pros:**
- ✅ Same language as frontend (TypeScript)
- ✅ Async native
- ✅ Fast enough (~5K req/sec)
- ✅ Full-stack JavaScript
- ✅ Good ecosystem

**Cons:**
- ❌ Need to rebuild (2 days)
- ❌ Weaker typing than PHP 8.4
- ❌ Callback hell (even with async/await)

**Performance:**
- ~5,000 req/sec
- Good balance

---

## Where's The Bottleneck?

**AskFiles performance breakdown:**

### Upload Flow
```
User uploads PDF (1-10 MB)
    ↓ [1-2 seconds] ← Backend receives, queues
Backend enqueues job
    ↓ [0.1 seconds] ← Backend returns immediately
Queue worker picks up job
    ↓ [5-30 seconds] ← **BOTTLENECK: Docling processing**
Extract text with Docling
    ↓ [2-10 seconds] ← **BOTTLENECK: OpenAI API**
Generate embeddings (OpenAI)
    ↓ [0.5-2 seconds] ← **BOTTLENECK: Network + Qdrant**
Store in Qdrant
    ↓ [0.1 seconds] ← Backend metadata update
Update database

Total: 8-44 seconds
Backend processing: <2 seconds (5% of total time)
```

### Search Flow
```
User searches
    ↓ [0.1 seconds] ← Backend receives query
Embed query (OpenAI)
    ↓ [0.5-1 second] ← **BOTTLENECK: OpenAI API**
Search Qdrant
    ↓ [0.1-0.5 seconds] ← **BOTTLENECK: Qdrant search**
Return results
    ↓ [0.05 seconds] ← Backend formats response

Total: 0.75-1.65 seconds
Backend processing: <0.2 seconds (12% of total time)
```

**Conclusion:** Backend framework is NOT the bottleneck. External services (OpenAI, Qdrant, Docling) are.

---

## Recommendation: Keep Laravel ✅

### Why?

1. **Time to Market**
   - Already set up and configured
   - Switching = 2-3 days lost
   - MVP needs to ship tonight

2. **Good Enough for MVP**
   - <1000 users: Laravel handles easily
   - Backend is <15% of total request time
   - External services are the bottleneck

3. **Better Ecosystem**
   - File uploads: Excellent
   - Queue system: Battle-tested
   - ORM: Simple and works
   - Packages: Everything we need exists

4. **Queue System**
   - Laravel queues are perfect for async document processing
   - Redis/database driver options
   - Retry logic built-in

5. **Not the Bottleneck**
   - OpenAI API: 0.5-2 seconds
   - Qdrant search: 0.1-0.5 seconds
   - Docling processing: 5-30 seconds
   - Laravel overhead: <0.2 seconds

**Making Laravel 10x faster wouldn't noticeably improve user experience.**

---

## When to Reconsider

### Red Flags (Time to Switch)

1. **>10K concurrent users**
   - Laravel starts to struggle
   - Consider: Go or Rust

2. **Real-time features needed**
   - WebSockets, SSE, streaming responses
   - Consider: Node.js or Go microservice alongside Laravel

3. **Document processing too slow**
   - Solution: Extract to Python microservice (not replace Laravel)
   - Keep Laravel for API/orchestration

4. **High CPU usage on backend**
   - If Laravel is >50% of request time
   - Then optimize or consider Go

---

## Better Architecture (Hybrid)

Instead of switching frameworks, **extract heavy processing:**

```
┌─────────────────────────────────────────────────────┐
│                   CURRENT (Laravel Does Everything) │
├─────────────────────────────────────────────────────┤
│                                                     │
│  Laravel API                                        │
│  ├── Receive upload                                 │
│  ├── Process with Docling (PHP exec)                │
│  ├── Call OpenAI                                    │
│  ├── Store in Qdrant                                │
│  └── Return response                                │
│                                                     │
└─────────────────────────────────────────────────────┘

Problem: If document processing is slow, entire backend is blocked.


┌─────────────────────────────────────────────────────┐
│              IMPROVED (Microservices)               │
├─────────────────────────────────────────────────────┤
│                                                     │
│  Laravel API (orchestration)                        │
│  ├── Receive upload                                 │
│  ├── Queue job                                      │
│  └── Return immediately                             │
│                                                     │
│  Python Microservice (processing)                   │
│  ├── Listen to queue                                │
│  ├── Process with Docling                           │
│  ├── Call OpenAI                                    │
│  ├── Store in Qdrant                                │
│  └── Update Laravel DB                              │
│                                                     │
└─────────────────────────────────────────────────────┘

Result: Laravel is fast, Python handles heavy work.
```

---

## Migration Path (If Needed Later)

### Phase 1: MVP (Now)
**Keep Laravel**, ship tonight

### Phase 2: Optimize (Week 2)
**Extract document processing** to Python microservice:
- Laravel receives upload, returns immediately
- Python worker processes documents
- Keeps Laravel for API/auth/metadata

### Phase 3: Scale (Month 2+)
**If needed**, add specialized services:
- Go service for real-time search results
- Rust service for high-throughput uploads
- Keep Laravel as main API gateway

**Do NOT rewrite everything.** Add services as needed.

---

## Decision Matrix

| If you need... | Use... | Why |
|----------------|--------|-----|
| **Ship tonight** | ✅ Laravel | Already set up |
| **<10K users** | ✅ Laravel | More than enough |
| **Simple CRUD API** | ✅ Laravel | Perfect fit |
| **Real-time features** | ⚠️ Add Node.js service | Alongside Laravel |
| **>10K concurrent** | ⚠️ Consider Go | Rewrite time |
| **ML/AI heavy** | ⚠️ Python microservice | Extract processing |
| **Extreme performance** | ⚠️ Rust | Overkill for most |

---

## Specific to AskFiles

**What AskFiles needs:**
1. File upload handling → ✅ Laravel excellent
2. Queue system → ✅ Laravel excellent
3. Metadata CRUD → ✅ Laravel excellent
4. External API calls → ✅ Laravel fine (not bottleneck)
5. Vector search → ⚠️ Qdrant handles this (separate)
6. Document processing → ⚠️ Python handles this (already)

**Verdict:** Laravel is the right choice for the orchestration layer.

---

## Cost Comparison (1000 users)

### Laravel
- VPS: $40/month (4GB RAM)
- Can handle 1000 users easily
- Total: **$40/month**

### Go (if we switched)
- VPS: $20/month (2GB RAM)
- Handles 1000 users easily
- Development time: +3 days
- Total: **$20/month + $3000 opportunity cost**

**ROI:** Save $20/month, lose 3 days of development = Not worth it for MVP

---

## Final Recommendation

### ✅ KEEP LARAVEL

**Reasons:**
1. Time to market (ship tonight vs 3 days delay)
2. Good enough for MVP (<10K users)
3. Not the bottleneck (external services are)
4. Better ecosystem for rapid development
5. Can always add microservices later

**Optimization strategy:**
1. **Now:** Use Laravel, ship MVP
2. **Week 2:** Extract Docling to Python microservice (if processing is slow)
3. **Month 2:** Add caching, optimize queries
4. **Month 3+:** Add specialized services only if needed

**Don't optimize prematurely.** Ship the MVP, measure real bottlenecks, then optimize.

---

## Alternative: If You Really Want Python

**Compromise:** Keep Laravel, but use FastAPI for document processing:

```
Laravel API (main)
├── Handles auth, metadata, API responses
└── Queues document processing jobs

FastAPI Microservice (worker)
├── Listens to queue
├── Processes documents with Docling
├── Calls OpenAI
├── Stores in Qdrant
└── Updates Laravel DB

Result: Best of both worlds
```

This would add 1-2 days but gives you Python for heavy processing.

---

**Your decision:** 
1. **Keep Laravel** (ship tonight) ← My recommendation
2. **Switch to FastAPI** (ship in 3 days)
3. **Hybrid** (Laravel + FastAPI microservice, ship in 2 days)

What matters most: **Speed to market** or **Perfect tech stack**?
